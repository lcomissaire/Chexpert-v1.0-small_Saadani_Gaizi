{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTOR-CRITIC LEARNING ALGORITHM (ACLA) FOR RADIOLOGIES OF CHESTS CLASSIFICATION INTO 14 CLUSTERS\n",
    "\n",
    "- Importing packages\n",
    "- creating the actor and critic neural networks\n",
    "- creating the secundary function of step and reward (environment)\n",
    "- creating the RL algorithm\n",
    "- Turning the images into n-vectors wich are inputs of the RL algorithm\n",
    "- importing data and testing (this section isn't finished yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from keras.preprocessing import image\n",
    "from keras import applications\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from torch.distributions import Categorical\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, memory_size, array):\n",
    "        self.memory_size = memory_size\n",
    "        self.buffer = collections.deque(array, maxlen=self.memory_size)\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if batch_size > len(self.buffer):\n",
    "            batch_size = len(self.buffer)\n",
    "        indexes = np.random.choice(np.arange(len(self.buffer)), size=batch_size, replace=False)\n",
    "        return [self.buffer[i] for i in indexes]\n",
    "\n",
    "    def clear(self):\n",
    "        self.buffer.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTOR AND CRITIC NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(AN, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.linear1 = nn.Linear(self.state_size, 128)\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        self.linear3 = nn.Linear(256, self.action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        output = F.relu(self.linear1(state))\n",
    "        output = F.relu(self.linear2(output))\n",
    "        output = self.linear3(output)\n",
    "        output = nn.functional.softmax(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(CN, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.linear1 = nn.Linear(self.state_size, 128)\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        self.linear3 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        output = F.relu(self.linear1(state))\n",
    "        output = F.relu(self.linear2(output))\n",
    "        value = self.linear3(output)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environments Function (Step, Reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(a, bucket):  #a is an int between 0 and 2n-1 \n",
    "    \n",
    "    res = list(bucket)\n",
    "    \n",
    "    if a < n:\n",
    "        res[n+a] = bucket[a]\n",
    "    else: \n",
    "        res[n+a] = 0\n",
    "        \n",
    "    return res\n",
    "\n",
    "def get_nbr_zero(bucket):\n",
    "    \n",
    "    res = 0\n",
    "    for b in bucket:\n",
    "        if b == 0:\n",
    "            res += 1\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "ALPHA = 0.5\n",
    "EXPLORE = 10000\n",
    "INITIAL_EPSILON = 0.1\n",
    "FINAL_EPSILON = 0.0001\n",
    "REPLAY_MEMORY = 2\n",
    "BATCH = 1\n",
    "n = 100\n",
    "h = 10\n",
    "    \n",
    "begin_learn = False\n",
    "learn_steps = 0\n",
    "episode_reward = 0\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_network = AN(3*n, 2*n).to(device)\n",
    "critic_network = CN(3*n, 2*n).to(device)\n",
    "optimizer_critic = torch.optim.Adam(critic_network.parameters(), lr=1e-4)\n",
    "optimizer_actor = torch.optim.Adam(actor_network.parameters(), lr=1e-4)\n",
    "\n",
    "memory_replay = Memory(REPLAY_MEMORY, collections.deque())\n",
    "\n",
    "\n",
    "rewards = []\n",
    "    \n",
    "    \n",
    "def rl(input_, h, flag):\n",
    "    \n",
    "    n = len(input_)\n",
    "    state = np.concatenate((list(input_),[0]*n, list(input_)))\n",
    "    state_tensor = torch.FloatTensor(state).to(device) \n",
    "    ep_reward = 0\n",
    "    hist_action = []\n",
    "    \n",
    "    for t in range(h):\n",
    "        \n",
    "        output = actor_network.forward(state_tensor) \n",
    "        output = output.argsort()\n",
    "        if flag == True:\n",
    "            for i in range(len(output)-1,-1,-1):\n",
    "                c = int(output[i])\n",
    "                if c not in hist_action:\n",
    "                    action = c\n",
    "                    hist_action.append(action)\n",
    "                    break\n",
    "            \n",
    "        else: \n",
    "            for i in range(0,len(output)):\n",
    "                c = int(output[i])\n",
    "                if c not in hist_action:\n",
    "                    action = c\n",
    "                    hist_action.append(action)\n",
    "                    break\n",
    "\n",
    "        next_state = step(action, state)\n",
    "        R_t = critic_network.forward(state_tensor)\n",
    "        reward = (1 - get_nbr_zero(state)/n)\n",
    "        ep_reward += reward\n",
    "        memory_replay.add((state, next_state, action, reward))\n",
    "        \n",
    "        \n",
    "        if memory_replay.size() > BATCH:\n",
    "            \n",
    "            batch = memory_replay.sample(BATCH)\n",
    "            batch_state, batch_next_state, batch_action, batch_reward = zip(*batch)\n",
    "            batch_state = torch.FloatTensor(batch_state).squeeze(1).to(device)\n",
    "            batch_next_state = torch.FloatTensor(batch_next_state).squeeze(1).to(device)\n",
    "            batch_action = torch.Tensor(batch_action).unsqueeze(1).to(device)\n",
    "            batch_reward = torch.Tensor(batch_reward).unsqueeze(1).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if t < h:\n",
    "                    R_t_next = critic_network.forward(batch_next_state) \n",
    "                    y = batch_reward + GAMMA*R_t_next\n",
    "                else:\n",
    "                    y = batch_reward \n",
    "              \n",
    "            delta = y - R_t_next \n",
    "            delta_normalize = []\n",
    "            for i in range(len(delta)):\n",
    "                if float(delta[i]) > 0:\n",
    "                    delta_normalize.append(1)\n",
    "                else: \n",
    "                    delta_normalize.append(0)\n",
    "\n",
    "\n",
    "            if flag == True:\n",
    "                loss_actor = torch.nn.BCELoss()(torch.FloatTensor(delta_normalize),torch.FloatTensor([1]*BATCH))\n",
    "            else:\n",
    "                loss_actor = torch.nn.BCELoss()(torch.FloatTensor(delta_normalize), torch.FloatTensor([0]*BATCH))\n",
    "            loss_actor.requires_grad = True\n",
    "            optimizer_actor.zero_grad()\n",
    "            loss_actor.backward()\n",
    "            optimizer_actor.step()\n",
    "\n",
    "        state = next_state\n",
    "        state_tensor = torch.FloatTensor(next_state).to(device) \n",
    "        \n",
    "    return (reward)\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing the Images with a VGG16 conv network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG16(include_top=True)       # weights = None or weights = imagenet ? \n",
    "\n",
    "def vectozize(path_):\n",
    "    \n",
    "    img = image.load_img(path = path_, target_size=(224, 224))\n",
    "    ary = image.img_to_array(img)\n",
    "    ary = np.expand_dims(ary, axis=0)\n",
    "    ary = preprocess_input(ary)\n",
    "    features = model.predict(ary)[0]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple : Training of the Edema recognizing Agent with our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "del train['Sex']\n",
    "del train['Age']\n",
    "del train['AP/PA']\n",
    "del train['Frontal/Lateral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_1 = train[train['Edema'] == 1]\n",
    "train_sample_2 = train[train['Edema'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_path_1 = train['Path'].tolist()\n",
    "list_path_2 = train_sample_2['Path'].tolist()\n",
    "inputs_1 = []\n",
    "inputs_2 = []\n",
    "\n",
    "for i in range (len(list_path_1)): \n",
    "\n",
    "    inputs_1.append(vectorize(list_path_1[i][20:]))\n",
    "    \n",
    "    if i%50 == 0:\n",
    "        print (i)\n",
    "    if i == 300:\n",
    "        break\n",
    "        \n",
    "for i in range (len(list_path_2)): \n",
    "   \n",
    "    inputs_2.append(vectorize(list_path_2[i][20:]))\n",
    "    \n",
    "    if i%50 == 0:\n",
    "        print (i)\n",
    "    if i == 300:\n",
    "        break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_ in inputs_1:\n",
    "    rl(input_h,True)\n",
    "for input_ in inputs_2:\n",
    "    rl(input_h,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.concatenate((list(inputs_1[0]),[0]*n, list(inputs_1[0])))\n",
    "critic_network(torch.FloatTensor(inp))\n",
    "\n",
    "inp_ = np.concatenate((list(inputs_2[0]),[0]*n, list(inputs_2[0])))\n",
    "critic_network(torch.FloatTensor(inp_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMEANS algorithm : Irelevant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.concatenate((inputs_1,inputs_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=13, random_state=0).fit(inputs_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 6, ..., 4, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0526], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = np.concatenate((list(inputs_1[0]),[0]*n, list(inputs_1[0])))\n",
    "critic_network(torch.FloatTensor(inp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
